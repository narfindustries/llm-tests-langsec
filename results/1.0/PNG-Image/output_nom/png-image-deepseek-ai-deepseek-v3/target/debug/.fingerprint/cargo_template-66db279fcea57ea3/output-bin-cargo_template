{"$message_type":"diagnostic","message":"unknown start of token: \\u{3002}","code":null,"level":"error","spans":[{"file_name":"src/main.rs","byte_start":3688,"byte_end":3691,"line_start":174,"line_end":174,"column_start":162,"column_end":163,"is_primary":true,"text":[{"text":"        b\"gAMA\" => parse_gama(chunk_data).map(|(_, gama)| Ch极速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速进一步优化代码补全最后部分。```rust","highlight_start":162,"highlight_end":163}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"Unicode character '。' (Ideographic Full Stop) looks like '.' (Period), but it is not","code":null,"level":"help","spans":[{"file_name":"src/main.rs","byte_start":3688,"byte_end":3691,"line_start":174,"line_end":174,"column_start":162,"column_end":163,"is_primary":true,"text":[{"text":"        b\"gAMA\" => parse_gama(chunk_data).map(|(_, gama)| Ch极速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速进一步优化代码补全最后部分。```rust","highlight_start":162,"highlight_end":163}],"label":null,"suggested_replacement":".","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror\u001b[0m\u001b[0m\u001b[1m: unknown start of token: \\u{3002}\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/main.rs:174:162\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m174.|....\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: Unicode character '。' (Ideographic Full Stop) looks like '.' (Period), but it is not\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m174\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        b\"gAMA\" => parse_gama(chunk_data).map(|(_, gama)| Ch极速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速进一步优化代码补全最后部分\u001b[0m\u001b[0m\u001b[38;5;10m.\u001b[0m\u001b[0m```rust\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                                                                                                                                                                                                                                       \u001b[0m\u001b[0m\u001b[38;5;10m~\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unknown start of token: `","code":null,"level":"error","spans":[{"file_name":"src/main.rs","byte_start":3691,"byte_end":3694,"line_start":174,"line_end":174,"column_start":163,"column_end":166,"is_primary":true,"text":[{"text":"        b\"gAMA\" => parse_gama(chunk_data).map(|(_, gama)| Ch极速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速进一步优化代码补全最后部分。```rust","highlight_start":163,"highlight_end":166}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"character appears 2 more times","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"Unicode character '`' (Grave Accent) looks like ''' (Single Quote), but it is not","code":null,"level":"help","spans":[{"file_name":"src/main.rs","byte_start":3691,"byte_end":3694,"line_start":174,"line_end":174,"column_start":163,"column_end":166,"is_primary":true,"text":[{"text":"        b\"gAMA\" => parse_gama(chunk_data).map(|(_, gama)| Ch极速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速进一步优化代码补全最后部分。```rust","highlight_start":163,"highlight_end":166}],"label":null,"suggested_replacement":"'''","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror\u001b[0m\u001b[0m\u001b[1m: unknown start of token: `\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/main.rs:174:163\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m174.|....\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;9m^^\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: character appears 2 more times\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: Unicode character '`' (Grave Accent) looks like ''' (Single Quote), but it is not\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m174\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        b\"gAMA\" => parse_gama(chunk_data).map(|(_, gama)| Ch极速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速进一步优化代码补全最后部分。\u001b[0m\u001b[0m\u001b[38;5;10m'''\u001b[0m\u001b[0mrust\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                                                                                                                                                                                                                                         \u001b[0m\u001b[0m\u001b[38;5;10m~~~\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"this file contains an unclosed delimiter","code":null,"level":"error","spans":[{"file_name":"src/main.rs","byte_start":2613,"byte_end":2614,"line_start":160,"line_end":160,"column_start":55,"column_end":56,"is_primary":false,"text":[{"text":"fn parse_chunk(input: &[u8]) -> IResult<&[u8], Chunk> {","highlight_start":55,"highlight_end":56}],"label":"unclosed delimiter","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/main.rs","byte_start":2840,"byte_end":2841,"line_start":166,"line_end":166,"column_start":34,"column_end":35,"is_primary":false,"text":[{"text":"    let chunk = match chunk_type {","highlight_start":34,"highlight_end":35}],"label":"unclosed delimiter","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/main.rs","byte_start":3370,"byte_end":3371,"line_start":174,"line_end":174,"column_start":46,"column_end":47,"is_primary":false,"text":[{"text":"        b\"gAMA\" => parse_gama(chunk_data).map(|(_, gama)| Ch极速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速进一步优化代码补全最后部分。```rust","highlight_start":46,"highlight_end":47}],"label":"unclosed delimiter","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/main.rs","byte_start":4903,"byte_end":4904,"line_start":206,"line_end":206,"column_start":53,"column_end":54,"is_primary":false,"text":[{"text":"fn parse_bkgd(input: &[u8]) -> IResult<&[u8], BKGD> {","highlight_start":53,"highlight_end":54}],"label":"unclosed delimiter","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/main.rs","byte_start":4947,"byte_end":4948,"line_start":207,"line_end":207,"column_start":43,"column_end":44,"is_primary":false,"text":[{"text":"    let (input, bkgd) = match input.len() {","highlight_start":43,"highlight_end":44}],"label":"unclosed delimiter","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/main.rs","byte_start":5015,"byte_end":5016,"line_start":209,"line_end":209,"column_start":17,"column_end":18,"is_primary":false,"text":[{"text":"        6 => map(tuple((be_u16, be_u","highlight_start":17,"highlight_end":18}],"label":"another 3 unclosed delimiters begin from here","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/main.rs","byte_start":5035,"byte_end":5035,"line_start":209,"line_end":209,"column_start":37,"column_end":37,"is_primary":true,"text":[{"text":"        6 => map(tuple((be_u16, be_u","highlight_start":37,"highlight_end":37}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror\u001b[0m\u001b[0m\u001b[1m: this file contains an unclosed delimiter\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/main.rs:209:37\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m160\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mfn parse_chunk(input: &[u8]) -> IResult<&[u8], Chunk> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                       \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12munclosed delimiter\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m...\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m166\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    let chunk = match chunk_type {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12munclosed delimiter\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m...\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m174\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        b\"gAMA\" => parse_gama(chunk_data).map(|(_, gama)| Ch极速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速\u001b[0m\u001b[0m                                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m...\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12munclosed delimiter\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m...\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m206\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mfn parse_bkgd(input: &[u8]) -> IResult<&[u8], BKGD> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12munclosed delimiter\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m207\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    let (input, bkgd) = match input.len() {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                           \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12munclosed delimiter\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m208\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        2 => map(be_u16, BKGD::Grayscale)(input),\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m209\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        6 => map(tuple((be_u16, be_u\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-\u001b[0m\u001b[0m                   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12manother 3 unclosed delimiters begin from here\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"aborting due to 3 previous errors","code":null,"level":"error","spans":[],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror\u001b[0m\u001b[0m\u001b[1m: aborting due to 3 previous errors\u001b[0m\n\n"}
